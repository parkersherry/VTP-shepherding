{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f08fa665-4a5e-4666-ae3f-64f66cc256ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base code from \n",
    "# 1: https://docs.opencv.org/4.x/da/d0c/tutorial_bounding_rects_circles.html\n",
    "# 2: https://pyimagesearch.com/2018/07/23/simple-object-tracking-with-opencv/\n",
    "# 3: https://www.geeksforgeeks.org/python/python-play-a-video-using-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "53bb811d-15e0-476b-9958-577f01225706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from scipy.spatial import distance as dist  # provides functions for computing distances\n",
    "from collections import OrderedDict \n",
    "import numpy as np  # y'all already know\n",
    "from __future__ import print_function\n",
    "import cv2 as cv\n",
    "import argparse\n",
    "import random as rng\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b6b1fd60-9aac-459a-a8d1-facd89eb66ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresh_callback(val, frame):\n",
    "    threshold = val\n",
    "    maxR = 10**(-4)\n",
    "    canny_output = cv.Canny(frame, threshold, threshold * 2)\n",
    "\n",
    "    contours, _ = cv.findContours(canny_output, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    # print(len(contours))\n",
    "\n",
    "    contours_poly = [None]*len(contours)\n",
    "    boundRect = []\n",
    "    skipped = []\n",
    "    centers = [None]*len(contours)\n",
    "    radius = [None]*len(contours)\n",
    "    for i, c in enumerate(contours):\n",
    "        contours_poly[i] = cv.approxPolyDP(c, 3, True)\n",
    "        centers[i], radius[i] = cv.minEnclosingCircle(contours_poly[i])\n",
    "        # print(radius[i])\n",
    "        # if radius[i] <= maxR:\n",
    "        boundRect.append(cv.boundingRect(contours_poly[i]))\n",
    "        # else:\n",
    "        #     skipped.append(c)\n",
    "        # print(len(boundRect[i]))      \n",
    "\n",
    "    drawing = np.zeros((canny_output.shape[0], canny_output.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    for i in range(len(boundRect)):\n",
    "        color = (rng.randint(0,256), rng.randint(0,256), rng.randint(0,256))\n",
    "        cv.drawContours(drawing, contours_poly, i, color)\n",
    "        cv.rectangle(drawing, (int(boundRect[i][0]), int(boundRect[i][1])), \\\n",
    "              (int(boundRect[i][0]+boundRect[i][2]), int(boundRect[i][1]+boundRect[i][3])), color, 2)\n",
    "        # cv.circle(drawing, (int(centers[i][0]), int(centers[i][1])), int(radius[i]), color, 2)\n",
    "\n",
    "    # cv.imshow('Contours', drawing)\n",
    "    # print(boundRect)\n",
    "    return boundRect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d2816839-ccb8-4823-80a6-c5d0e5844f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CentroidTracker():\n",
    "\tdef __init__(self, maxDisappeared=100):\n",
    "\t\tself.objects = OrderedDict()\n",
    "\t\tself.nextObjectID = 0\n",
    "\t\tself.disappeared = OrderedDict()\n",
    "\t\tself.Positions = OrderedDict()\n",
    "\t\tself.maxDisappeared = maxDisappeared\n",
    "\t\n",
    "\tdef update_Positions(self,frameNumber,CX,CY):\n",
    "\t\tobjectIDs = list(CX.keys())\n",
    "    \t# objectCentroids = list(self.objects.values())\n",
    "\t\tfor ID in objectIDs:\n",
    "\t\t\tif ID in self.Positions:\n",
    "\t\t\t\tself.Positions[ID] = np.append(self.Positions[ID],np.array([[frameNumber,CX[ID],CY[ID]]]),axis=0)\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.Positions[ID] = np.array([[frameNumber,CX[ID],CY[ID]]])\n",
    "\t\n",
    "\tdef register(self, centroid):\n",
    "\t\t# when registering an object we use the next available object\n",
    "\t\t# ID to store the centroid\n",
    "\t\tself.objects[self.nextObjectID] = centroid\n",
    "\t\tself.disappeared[self.nextObjectID] = 0\n",
    "\t\tself.nextObjectID += 1\n",
    "\t\n",
    "\tdef deregister(self, objectID):\n",
    "\t\t# to deregister an object ID we delete the object ID from\n",
    "\t\t# both of our respective dictionaries\n",
    "\t\tdel self.objects[objectID]\n",
    "\t\tdel self.disappeared[objectID]\n",
    "\t\n",
    "\tdef update(self, rects):\n",
    "\t\t# check to see if the list of input bounding box rectangles\n",
    "\t\t# is empty\n",
    "\t\tif len(rects) == 0:\n",
    "\t\t\t# loop over any existing tracked objects and mark them\n",
    "\t\t\t# as disappeared\n",
    "\t\t\tfor objectID in list(self.disappeared.keys()):\n",
    "\t\t\t\tself.disappeared[objectID] += 1\n",
    "\t\t\t\t# if we have reached a maximum number of consecutive\n",
    "\t\t\t\t# frames where a given object has been marked as\n",
    "\t\t\t\t# missing, deregister it\n",
    "\t\t\t\tif self.disappeared[objectID] > self.maxDisappeared:\n",
    "\t\t\t\t\tself.deregister(objectID)\n",
    "\t\t\t# return early as there are no centroids or tracking info\n",
    "\t\t\t# to update\n",
    "\t\t\treturn self.objects\n",
    "\n",
    "        # initialize an array of input centroids for the current frame\n",
    "\t\tinputCentroids = np.zeros((len(rects), 2), dtype='int')\n",
    "        # loop over the bounding box rectangles\n",
    "\t\tCX = OrderedDict()\n",
    "\t\tCY = OrderedDict()\n",
    "\t\tfor (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
    "            # use the bounding box coordinates to derive the centroid\n",
    "\t\t\tcX = int((startX + endX) / 2.0)\n",
    "\t\t\tcY = int((startY + endY) / 2.0)\n",
    "\t\t\tinputCentroids[i] = (cX, cY)\n",
    "\n",
    "        # if we are currently not tracking any objects take the input\n",
    "\t\t# centroids and register each of them\n",
    "\t\tif len(self.objects) == 0:\n",
    "\t\t\tfor i in range(0, len(inputCentroids)):\n",
    "\t\t\t\tself.register(inputCentroids[i])\n",
    "        # otherwise, are are currently tracking objects so we need to\n",
    "\t\t# try to match the input centroids to existing object\n",
    "\t\t# centroids\n",
    "\t\telse:\n",
    "\t\t\t# grab the set of object IDs and corresponding centroids\n",
    "\t\t\tobjectIDs = list(self.objects.keys())\n",
    "\t\t\tobjectCentroids = list(self.objects.values())\n",
    "\t\t\t# compute the distance between each pair of object\n",
    "\t\t\t# centroids and input centroids, respectively -- our\n",
    "\t\t\t# goal will be to match an input centroid to an existing\n",
    "\t\t\t# object centroid\n",
    "\t\t\tD = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
    "\t\t\t# in order to perform this matching we must (1) find the\n",
    "\t\t\t# smallest value in each row and then (2) sort the row\n",
    "\t\t\t# indexes based on their minimum values so that the row\n",
    "\t\t\t# with the smallest value is at the *front* of the index\n",
    "\t\t\t# list\n",
    "\t\t\trows = D.min(axis=1).argsort()\n",
    "\t\t\t# next, we perform a similar process on the columns by\n",
    "\t\t\t# finding the smallest value in each column and then\n",
    "\t\t\t# sorting using the previously computed row index list\n",
    "\t\t\tcols = D.argmin(axis=1)[rows]\n",
    "\n",
    "            # in order to determine if we need to update, register,\n",
    "\t\t\t# or deregister an object we need to keep track of which\n",
    "\t\t\t# of the rows and column indexes we have already examined\n",
    "\t\t\tusedRows = set()\n",
    "\t\t\tusedCols = set()\n",
    "\t\t\t# loop over the combination of the (row, column) index\n",
    "\t\t\t# tuples\n",
    "\t\t\tfor (row, col) in zip(rows, cols):\n",
    "\t\t\t\t# if we have already examined either the row or\n",
    "\t\t\t\t# column value before, ignore it\n",
    "\t\t\t\t# val\n",
    "\t\t\t\tif row in usedRows or col in usedCols:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\t# otherwise, grab the object ID for the current row,\n",
    "\t\t\t\t# set its new centroid, and reset the disappeared\n",
    "\t\t\t\t# counter\n",
    "\t\t\t\tobjectID = objectIDs[row]\n",
    "\t\t\t\tself.objects[objectID] = inputCentroids[col]\n",
    "\t\t\t\tCX[objectID] = inputCentroids[col][0]\n",
    "\t\t\t\tCY[objectID] = inputCentroids[col][1]\n",
    "\t\t\t\tself.disappeared[objectID] = 0\n",
    "\t\t\t\t# indicate that we have examined each of the row and\n",
    "\t\t\t\t# column indexes, respectively\n",
    "\t\t\t\tusedRows.add(row)\n",
    "\t\t\t\tusedCols.add(col)\n",
    "\t\t\t# compute both the row and column index we have NOT yet\n",
    "\t\t\t# examined\n",
    "\t\t\tunusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "\t\t\tunusedCols = set(range(0, D.shape[1])).difference(usedCols)   \n",
    "            # in the event that the number of object centroids is\n",
    "\t\t\t# equal or greater than the number of input centroids\n",
    "\t\t\t# we need to check and see if some of these objects have\n",
    "\t\t\t# potentially disappeared\n",
    "\t\t\tif D.shape[0] >= D.shape[1]:\n",
    "\t\t\t\t# loop over the unused row indexes\n",
    "\t\t\t\tfor row in unusedRows:\n",
    "\t\t\t\t\t# grab the object ID for the corresponding row\n",
    "\t\t\t\t\t# index and increment the disappeared counter\n",
    "\t\t\t\t\tobjectID = objectIDs[row]\n",
    "\t\t\t\t\tself.disappeared[objectID] += 1\n",
    "\t\t\t\t\t# check to see if the number of consecutive\n",
    "\t\t\t\t\t# frames the object has been marked \"disappeared\"\n",
    "\t\t\t\t\t# for warrants deregistering the object\n",
    "\t\t\t\t\tif self.disappeared[objectID] > self.maxDisappeared:\n",
    "\t\t\t\t\t\tself.deregister(objectID)\n",
    "            # otherwise, if the number of input centroids is greater\n",
    "\t\t\t# than the number of existing object centroids we need to\n",
    "\t\t\t# register each new input centroid as a trackable object\n",
    "\t\t\telse:\n",
    "\t\t\t\tfor col in unusedCols:\n",
    "\t\t\t\t\tself.register(inputCentroids[col])\n",
    "\t\t# return the set of trackable objects\n",
    "\t\treturn self.objects, CX, CY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0132b212-4a5d-4927-802b-a934436b323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WaterShed(frame):\n",
    "\n",
    "    src = frame\n",
    "    if src is None:\n",
    "        print('Could not open or find the image')\n",
    "        exit(0)\n",
    "    # Show source image\n",
    "    # cv.imshow('Source Image', src)\n",
    "    \n",
    "    #----------------------------#\n",
    "    kernel = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]], dtype=np.float32)\n",
    "    # do the laplacian filtering as it is\n",
    "    # well, we need to convert everything in something more deeper then CV_8U\n",
    "    # because the kernel has some negative values,\n",
    "    # and we can expect in general to have a Laplacian image with negative values\n",
    "    # BUT a 8bits unsigned int (the one we are working with) can contain values from 0 to 255\n",
    "    # so the possible negative number will be truncated\n",
    "    imgLaplacian = cv.filter2D(src, cv.CV_32F, kernel)\n",
    "    sharp = np.float32(src)\n",
    "    imgResult = sharp - imgLaplacian\n",
    "    \n",
    "    #-----------------------------#\n",
    "    # convert back to 8bits gray scale\n",
    "    imgResult = np.clip(imgResult, 0, 255)\n",
    "    imgResult = imgResult.astype('uint8')\n",
    "    imgLaplacian = np.clip(imgLaplacian, 0, 255)\n",
    "    imgLaplacian = np.uint8(imgLaplacian)\n",
    "    #cv.imshow('Laplace Filtered Image', imgLaplacian)\n",
    "    # cv.imshow('New Sharped Image', imgResult)\n",
    "    #------------------------------------------#\n",
    "    \n",
    "    # cv.waitKey(0)\n",
    "    # cv.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    #get binary image\n",
    "    bw = cv.cvtColor(imgResult, cv.COLOR_BGR2GRAY)\n",
    "    _, bw = cv.threshold(bw, 40, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n",
    "    # cv.imshow('Binary Image', bw)\n",
    "    # cv.waitKey(0)\n",
    "    # cv.destroyAllWindows()\n",
    "    \n",
    "    dist = cv.distanceTransform(bw, cv.DIST_L2, 3)\n",
    "    # Normalize the distance image for range = {0.0, 1.0}\n",
    "    # so we can visualize and threshold it\n",
    "    cv.normalize(dist, dist, 0, 1.0, cv.NORM_MINMAX)\n",
    "    # cv.imshow('Distance Transform Image', dist)\n",
    "    # cv.waitKey(0)\n",
    "    # cv.destroyAllWindows()\n",
    "    \n",
    "    _, dist = cv.threshold(dist, 0.4, 1.0, cv.THRESH_BINARY)\n",
    "    # Dilate a bit the dist image\n",
    "    kernel1 = np.ones((3,3), dtype=np.uint8)\n",
    "    dist = cv.dilate(dist, kernel1)\n",
    "    # cv.imshow('Peaks', dist)\n",
    "    # cv.waitKey(0)\n",
    "    # cv.destroyAllWindows()\n",
    "    \n",
    "    dist_8u = dist.astype('uint8')\n",
    "    # print(np.max(dist_8u))\n",
    "    # Find total markers\n",
    "    contours, _ = cv.findContours(dist_8u, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    # Create the marker image for the watershed algorithm\n",
    "    markers = np.zeros(dist.shape, dtype=np.int32)\n",
    "    # Draw the foreground markers\n",
    "    for i in range(len(contours)):\n",
    "        cv.drawContours(markers, contours, i, (i+1), -1)\n",
    "    # Draw the background marker\n",
    "    cv.circle(markers, (5,5), 3, (255,255,255), -1)\n",
    "    markers_8u = (markers * 10).astype('uint8')\n",
    "    # cv.imshow('Markers', markers_8u)\n",
    "    # cv.waitKey(0)\n",
    "    # cv.destroyAllWindows()\n",
    "    \n",
    "    cv.watershed(imgResult, markers)\n",
    "    #mark = np.zeros(markers.shape, dtype=np.uint8)\n",
    "    mark = markers.astype('uint8')\n",
    "    mark = cv.bitwise_not(mark)\n",
    "    # uncomment this if you want to see how the mark\n",
    "    # image looks like at that point\n",
    "    #cv.imshow('Markers_v2', mark)\n",
    "    # Generate random colors\n",
    "    colors = []\n",
    "    for contour in contours:\n",
    "        colors.append((rng.randint(0,255), rng.randint(0,255), rng.randint(0,255)))\n",
    "    # Create the result image\n",
    "    dst = np.zeros((markers.shape[0], markers.shape[1], 3), dtype=np.uint8)\n",
    "    # Fill labeled objects with random colors\n",
    "    for i in range(markers.shape[0]):\n",
    "        for j in range(markers.shape[1]):\n",
    "            index = markers[i,j]\n",
    "            if index > 0 and index <= len(contours):\n",
    "                dst[i,j,:] = colors[index-1]\n",
    "    \n",
    "    return dst\n",
    "    \n",
    "    # Visualize the final image\n",
    "    # cv.imshow('Final Result', dst)\n",
    "    # cv.waitKey()\n",
    "    # cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2b805806-1c7f-465a-96c4-0bc5c9b5ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_video(filename, thresh):\n",
    "    # Create a VideoCapture object and read from input file\n",
    "    cap = cv.VideoCapture(filename)\n",
    "    \n",
    "    # Check if camera opened successfully\n",
    "    if (cap.isOpened()== False):\n",
    "        print(\"Error opening video file\")\n",
    "    cTracker = CentroidTracker()\n",
    "    fgbg = cv.bgsegm.createBackgroundSubtractorMOG()\n",
    "\n",
    "    # Read until video is completed\n",
    "    t=0\n",
    "    # a=7;\n",
    "    # kernel1 = cv.getStructuringElement(cv.MORPH_RECT,(a,a))\n",
    "    # kernel2 = cv.getStructuringElement(cv.MORPH_CROSS,(a,a))\n",
    "    # kernel3 = cv.getStructuringElement(cv.MORPH_ELLIPSE,(a,a))\n",
    "    numGuys = []\n",
    "    # frameDim = 500;\n",
    "    while(cap.isOpened()):\n",
    "        t+=1\n",
    "    # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            # fgmask = fgbg.apply(frame)\n",
    "            # fgmask1 = cv.morphologyEx(fgmask, cv.MORPH_OPEN, kernel1)\n",
    "            # fgmask2 = cv.morphologyEx(fgmask, cv.MORPH_OPEN, kernel2)\n",
    "            # fgmask3 = cv.morphologyEx(fgmask, cv.MORPH_OPEN, kernel3)\n",
    "            # cv.imshow('frame1',fgmask1)\n",
    "            # cv.resizeWindow('frame1', frameDim,frameDim)\n",
    "            # cv.imshow('frame2',fgmask2)\n",
    "            # cv.resizeWindow('frame2', frameDim,frameDim)\n",
    "            # cv.imshow('frame3',fgmask3)\n",
    "            # cv.resizeWindow('frame3', frameDim,frameDim)\n",
    "            #k = cv.waitKey(30) & 0xff\n",
    "\n",
    "            # Display the resulting frame\n",
    "            # frame = WaterShed(frame)\n",
    "\n",
    "            hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "            sensitivity = 25\n",
    "            lower_white = np.array([0, 0, 255-sensitivity])\n",
    "            upper_white = np.array([255, sensitivity, 255])\n",
    "            mask = cv.inRange(hsv, lower_white, upper_white)\n",
    "            inv_mask = cv.bitwise_not(mask)\n",
    "            \n",
    "            frame = cv.bitwise_and(frame, frame, mask = mask)\n",
    "            \n",
    "            cv.imshow('frame', frame)\n",
    "            rects = thresh_callback(thresh, frame)\n",
    "            # cv.resizeWindow('Contours', frameDim,frameDim)\n",
    "            if cv.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "            if not rects:\n",
    "                continue\n",
    "            objects,CX,CY = cTracker.update(rects)\n",
    "            numGuys.append(len(objects))\n",
    "            cTracker.update_Positions(t,CX,CY)\n",
    "            # print(len(rects))\n",
    "            # Press Q on keyboard to exit\n",
    "            \n",
    "\n",
    "    # Break the loop\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # When everything done, release\n",
    "    # the video capture object\n",
    "    cap.release()\n",
    "    # print(cTracker.Positions)\n",
    "    # K=(len(list(cTracker.Positions.keys())))\n",
    "    # print(K)\n",
    "    # print(\"------------------------\")\n",
    "    # for k in list(cTracker.Positions.keys()):\n",
    "    #     print(np.size(cTracker.Positions[k])/3)\n",
    "    # Closes all the frames\n",
    "    \n",
    "    cv.destroyAllWindows()\n",
    "    return numGuys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b1403b0e-56e3-42cc-b60f-46ff950552b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numGuys = init_video(\"sheepvid4.mp4\", 200)\n",
    "# plt.hist(numGuys)\n",
    "# plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b047836",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94969641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
